{"metadata":{"colab":{"name":"Summarization","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8266474,"sourceType":"datasetVersion","datasetId":4811790}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install datasets evaluate transformers rouge-score nltk","metadata":{"id":"MOsHUjgdIrIW","execution":{"iopub.status.busy":"2024-04-30T13:09:35.204513Z","iopub.execute_input":"2024-04-30T13:09:35.204920Z","iopub.status.idle":"2024-04-30T13:09:47.853276Z","shell.execute_reply.started":"2024-04-30T13:09:35.204889Z","shell.execute_reply":"2024-04-30T13:09:47.852285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"id":"Xs_cs9GNlbqh","execution":{"iopub.status.busy":"2024-04-30T13:09:51.799709Z","iopub.execute_input":"2024-04-30T13:09:51.800189Z","iopub.status.idle":"2024-04-30T13:09:51.824828Z","shell.execute_reply.started":"2024-04-30T13:09:51.800149Z","shell.execute_reply":"2024-04-30T13:09:51.823858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt install git-lfs","metadata":{"id":"kS7IPjJ8lbqi","execution":{"iopub.status.busy":"2024-04-30T13:10:10.735207Z","iopub.execute_input":"2024-04-30T13:10:10.735554Z","iopub.status.idle":"2024-04-30T13:10:13.446042Z","shell.execute_reply.started":"2024-04-30T13:10:10.735529Z","shell.execute_reply":"2024-04-30T13:10:13.444892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\n\nprint(transformers.__version__)","metadata":{"id":"-cN-1K5tlbqi","execution":{"iopub.status.busy":"2024-04-30T13:10:17.283224Z","iopub.execute_input":"2024-04-30T13:10:17.284033Z","iopub.status.idle":"2024-04-30T13:10:17.289379Z","shell.execute_reply.started":"2024-04-30T13:10:17.283998Z","shell.execute_reply":"2024-04-30T13:10:17.288218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers.utils import send_example_telemetry\n\nsend_example_telemetry(\"summarization_notebook\", framework=\"pytorch\")","metadata":{"id":"wQZui_6Tlbqj","execution":{"iopub.status.busy":"2024-04-30T13:10:44.606340Z","iopub.execute_input":"2024-04-30T13:10:44.606753Z","iopub.status.idle":"2024-04-30T13:10:44.615056Z","shell.execute_reply.started":"2024-04-30T13:10:44.606721Z","shell.execute_reply":"2024-04-30T13:10:44.613865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = \"t5-small\"","metadata":{"id":"D5uqV1yNlbqk","execution":{"iopub.status.busy":"2024-04-30T13:10:49.161662Z","iopub.execute_input":"2024-04-30T13:10:49.162529Z","iopub.status.idle":"2024-04-30T13:10:49.166440Z","shell.execute_reply.started":"2024-04-30T13:10:49.162493Z","shell.execute_reply":"2024-04-30T13:10:49.165463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom evaluate import load\n\nmetric = load(\"rouge\")","metadata":{"id":"IreSlFmlIrIm","outputId":"efa20b05-1023-4a19-dae8-810e180762d6","execution":{"iopub.status.busy":"2024-04-30T13:10:53.090615Z","iopub.execute_input":"2024-04-30T13:10:53.091284Z","iopub.status.idle":"2024-04-30T13:10:53.654798Z","shell.execute_reply.started":"2024-04-30T13:10:53.091252Z","shell.execute_reply":"2024-04-30T13:10:53.654045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\n# Charger le fichier CSV avec pandas\ndf = pd.read_csv(\"/kaggle/input/pfe-1-1/output1.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:10:56.891574Z","iopub.execute_input":"2024-04-30T13:10:56.891917Z","iopub.status.idle":"2024-04-30T13:11:24.716469Z","shell.execute_reply.started":"2024-04-30T13:10:56.891891Z","shell.execute_reply":"2024-04-30T13:11:24.715640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Sélectionner les colonnes \"cleaned_text\" et \"abstract\"\ndf = df[['cleaned_text','shorter_abstract']]\n# Afficher le DataFrame avec les colonnes sélectionnées\ndf","metadata":{"id":"X6HrpprwIrIz","outputId":"d7670bc0-42e4-4c09-8a6a-5c018ded7d95","execution":{"iopub.status.busy":"2024-04-30T13:11:30.280393Z","iopub.execute_input":"2024-04-30T13:11:30.280752Z","iopub.status.idle":"2024-04-30T13:11:30.326653Z","shell.execute_reply.started":"2024-04-30T13:11:30.280724Z","shell.execute_reply":"2024-04-30T13:11:30.325721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntest_size = 0.2\n\ntrain_df, test_df = train_test_split(df, test_size=test_size, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:11:35.603215Z","iopub.execute_input":"2024-04-30T13:11:35.603585Z","iopub.status.idle":"2024-04-30T13:11:35.616929Z","shell.execute_reply.started":"2024-04-30T13:11:35.603557Z","shell.execute_reply":"2024-04-30T13:11:35.616138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:11:38.038496Z","iopub.execute_input":"2024-04-30T13:11:38.039354Z","iopub.status.idle":"2024-04-30T13:11:38.054632Z","shell.execute_reply.started":"2024-04-30T13:11:38.039310Z","shell.execute_reply":"2024-04-30T13:11:38.053649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter rows where the type of 'shorter_abstract' column is not string\nnon_string_rows_index = train_df[~train_df['shorter_abstract'].apply(lambda x: isinstance(x, str))].index\n\n# Drop the rows\ntrain_df.drop(index=non_string_rows_index, inplace=True)\n\n# Reset the index after dropping rows\ntrain_df.reset_index(drop=True, inplace=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:11:45.948532Z","iopub.execute_input":"2024-04-30T13:11:45.949277Z","iopub.status.idle":"2024-04-30T13:11:45.990398Z","shell.execute_reply.started":"2024-04-30T13:11:45.949241Z","shell.execute_reply":"2024-04-30T13:11:45.989256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:11:52.653821Z","iopub.execute_input":"2024-04-30T13:11:52.654713Z","iopub.status.idle":"2024-04-30T13:11:52.666296Z","shell.execute_reply.started":"2024-04-30T13:11:52.654677Z","shell.execute_reply":"2024-04-30T13:11:52.665369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter rows where the type of 'shorter_abstract' column is not string\nnon_string_rows_index = test_df[~test_df['shorter_abstract'].apply(lambda x: isinstance(x, str))].index\n\n# Drop the rows\ntest_df.drop(index=non_string_rows_index, inplace=True)\n\n# Reset the index after dropping rows\ntest_df.reset_index(drop=True, inplace=True)\ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:11:57.684111Z","iopub.execute_input":"2024-04-30T13:11:57.684788Z","iopub.status.idle":"2024-04-30T13:11:57.704434Z","shell.execute_reply.started":"2024-04-30T13:11:57.684752Z","shell.execute_reply":"2024-04-30T13:11:57.703410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:12:04.058557Z","iopub.execute_input":"2024-04-30T13:12:04.059405Z","iopub.status.idle":"2024-04-30T13:12:04.070961Z","shell.execute_reply.started":"2024-04-30T13:12:04.059374Z","shell.execute_reply":"2024-04-30T13:12:04.069906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Assuming train_df is already defined\ndef word_counter(text):\n    return len(text.split())\n\n# Calculate the length of text in each column\ntrain_df['cleaned_text_length'] = train_df['cleaned_text'].apply(word_counter)\ntrain_df['shorter_abstract_length'] = train_df['shorter_abstract'].apply(word_counter)\n\n# Get the maximum length in each column\nmax_cleaned_text_length = train_df['cleaned_text_length'].max()\nmax_shorter_abstract_length = train_df['shorter_abstract_length'].max()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:12:10.085035Z","iopub.execute_input":"2024-04-30T13:12:10.085670Z","iopub.status.idle":"2024-04-30T13:12:15.326170Z","shell.execute_reply.started":"2024-04-30T13:12:10.085636Z","shell.execute_reply":"2024-04-30T13:12:15.325120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_cleaned_text_length","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:12:17.950988Z","iopub.execute_input":"2024-04-30T13:12:17.951357Z","iopub.status.idle":"2024-04-30T13:12:17.957322Z","shell.execute_reply.started":"2024-04-30T13:12:17.951330Z","shell.execute_reply":"2024-04-30T13:12:17.956351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_shorter_abstract_length","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:12:22.138537Z","iopub.execute_input":"2024-04-30T13:12:22.138835Z","iopub.status.idle":"2024-04-30T13:12:22.144386Z","shell.execute_reply.started":"2024-04-30T13:12:22.138812Z","shell.execute_reply":"2024-04-30T13:12:22.143497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the histogram for cleaned_text column\nplt.figure(figsize=(10, 6))\nplt.hist(train_df['cleaned_text_length'], bins=50, color='skyblue', edgecolor='black')\nplt.title('Length Distribution of cleaned_text')\nplt.xlabel('Text Length')\nplt.ylabel('Frequency')\nplt.axvline(x=max_cleaned_text_length, color='red', linestyle='--', label=f'Max Length: {max_cleaned_text_length}')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:12:28.590615Z","iopub.execute_input":"2024-04-30T13:12:28.591230Z","iopub.status.idle":"2024-04-30T13:12:29.041398Z","shell.execute_reply.started":"2024-04-30T13:12:28.591197Z","shell.execute_reply":"2024-04-30T13:12:29.040502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the histogram for shorter_abstract column\nplt.figure(figsize=(10, 6))\nplt.hist(train_df['shorter_abstract_length'], bins=50, color='lightgreen', edgecolor='black')\nplt.title('Length Distribution of shorter_abstract')\nplt.xlabel('Text Length')\nplt.ylabel('Frequency')\nplt.axvline(x=max_shorter_abstract_length, color='red', linestyle='--', label=f'Max Length: {max_shorter_abstract_length}')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:12:35.073669Z","iopub.execute_input":"2024-04-30T13:12:35.074323Z","iopub.status.idle":"2024-04-30T13:12:35.485920Z","shell.execute_reply.started":"2024-04-30T13:12:35.074293Z","shell.execute_reply":"2024-04-30T13:12:35.484943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\n# Assuming you already have pandas DataFrames 'train_df' and 'test_df'\n\n# Convert pandas DataFrames to Hugging Face Dataset\ntrain_dataset = Dataset.from_pandas(train_df[['cleaned_text','shorter_abstract']].head(20000))\ntest_dataset = Dataset.from_pandas(test_df.head(6000))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:12:47.320108Z","iopub.execute_input":"2024-04-30T13:12:47.320620Z","iopub.status.idle":"2024-04-30T13:12:52.078426Z","shell.execute_reply.started":"2024-04-30T13:12:47.320573Z","shell.execute_reply":"2024-04-30T13:12:52.077611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import DatasetDict\ndataset = DatasetDict({\n    'train':train_dataset,\n    'test':test_dataset\n})\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:12:54.862679Z","iopub.execute_input":"2024-04-30T13:12:54.863037Z","iopub.status.idle":"2024-04-30T13:12:54.870004Z","shell.execute_reply.started":"2024-04-30T13:12:54.863008Z","shell.execute_reply":"2024-04-30T13:12:54.869048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"id":"eXNLu_-nIrJI","execution":{"iopub.status.busy":"2024-04-30T13:13:02.049934Z","iopub.execute_input":"2024-04-30T13:13:02.050698Z","iopub.status.idle":"2024-04-30T13:13:03.379594Z","shell.execute_reply.started":"2024-04-30T13:13:02.050660Z","shell.execute_reply":"2024-04-30T13:13:03.378527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_input_length = 1024\nmax_target_length = 256\n\ndef preprocess_function(examples):\n    inputs = [\"summarize: \" + doc for doc in examples[\"cleaned_text\"]]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n\n    # Setup the tokenizer for targets\n    labels = tokenizer(text_target=examples[\"shorter_abstract\"], max_length=max_target_length, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"id":"vc0BSBLIIrJQ","execution":{"iopub.status.busy":"2024-04-30T13:13:05.047380Z","iopub.execute_input":"2024-04-30T13:13:05.048160Z","iopub.status.idle":"2024-04-30T13:13:05.054447Z","shell.execute_reply.started":"2024-04-30T13:13:05.048119Z","shell.execute_reply":"2024-04-30T13:13:05.053312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset, DatasetDict\n\n# Charger le CSV dans un DataFrame pandas\ndf = pd.read_csv(\"/kaggle/input/pfe-1-1/output.csv\")\n\n# Limiter la taille de votre DataFrame (par exemple, aux 1000 premières lignes)\nlimited_df = df.head(1000)\n\n# Convertir le DataFrame en Dataset\ntrain_dataset = Dataset.from_pandas(limited_df)\n\n# Définir une fonction de prétraitement\ndef preprocess_function(examples):\n    # Prétraitement des exemples ici\n    return examples\n\n# Appliquer la fonction de prétraitement à l'ensemble de données\npreprocessed_dataset = train_dataset.map(preprocess_function)\n\n# Créer un DatasetDict contenant les ensembles d'entraînement et de test\ndataset = DatasetDict({\n    'train': preprocessed_dataset,\n    'test': preprocessed_dataset,\n})\n\n# Exemple d'utilisation de la fonction preprocess_function\npreprocess_function(dataset['train'][:2])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:09:31.770890Z","iopub.status.idle":"2024-04-30T13:09:31.771245Z","shell.execute_reply.started":"2024-04-30T13:09:31.771058Z","shell.execute_reply":"2024-04-30T13:09:31.771071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:13:08.979526Z","iopub.execute_input":"2024-04-30T13:13:08.979924Z","iopub.status.idle":"2024-04-30T13:13:08.985795Z","shell.execute_reply.started":"2024-04-30T13:13:08.979894Z","shell.execute_reply":"2024-04-30T13:13:08.984856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Appliquer la fonction de prétraitement à l'ensemble de données\ntokenized_datasets = dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:13:13.028315Z","iopub.execute_input":"2024-04-30T13:13:13.028675Z","iopub.status.idle":"2024-04-30T13:16:26.353978Z","shell.execute_reply.started":"2024-04-30T13:13:13.028647Z","shell.execute_reply":"2024-04-30T13:16:26.353059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\nmodel_name = \"t5-small\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n# Enregistrez le modèle checkpoint dans un répertoire spécifié\nmodel.save_pretrained(\"/kaggle/working/t5-small-checkpoint\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:19:19.409057Z","iopub.execute_input":"2024-04-30T13:19:19.409466Z","iopub.status.idle":"2024-04-30T13:19:22.471169Z","shell.execute_reply.started":"2024-04-30T13:19:19.409437Z","shell.execute_reply":"2024-04-30T13:19:22.470320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = \"/kaggle/working/t5-small-checkpoint\"\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:19:25.105809Z","iopub.execute_input":"2024-04-30T13:19:25.106208Z","iopub.status.idle":"2024-04-30T13:19:25.110513Z","shell.execute_reply.started":"2024-04-30T13:19:25.106176Z","shell.execute_reply":"2024-04-30T13:19:25.109529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\n# model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"id":"TlqNaB8jIrJW","execution":{"iopub.status.busy":"2024-04-30T13:19:29.781730Z","iopub.execute_input":"2024-04-30T13:19:29.782099Z","iopub.status.idle":"2024-04-30T13:19:29.809637Z","shell.execute_reply.started":"2024-04-30T13:19:29.782057Z","shell.execute_reply":"2024-04-30T13:19:29.808905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\nmodel_name = model_checkpoint.split(\"/\")[-1]\nargs = Seq2SeqTrainingArguments(\n    f\"{model_name}-finetuned-pav1\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.001,\n    save_total_limit=1,\n    num_train_epochs=6,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=False,\n    fp16_full_eval=False  # Désactiver la précision en demi-précision pour l'évaluation\n)","metadata":{"id":"prkfNrbnlbqv","execution":{"iopub.status.busy":"2024-04-30T13:19:34.176347Z","iopub.execute_input":"2024-04-30T13:19:34.176716Z","iopub.status.idle":"2024-04-30T13:19:34.251242Z","shell.execute_reply.started":"2024-04-30T13:19:34.176686Z","shell.execute_reply":"2024-04-30T13:19:34.250463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvcc --version\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:19:38.102721Z","iopub.execute_input":"2024-04-30T13:19:38.103082Z","iopub.status.idle":"2024-04-30T13:19:39.207727Z","shell.execute_reply.started":"2024-04-30T13:19:38.103052Z","shell.execute_reply":"2024-04-30T13:19:39.206622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n!sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n!wget http://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.3-450.51.06-1_amd64.deb\n!sudo dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.3-450.51.06-1_amd64.deb\n!sudo apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n!sudo apt-get update\n!sudo apt-get -y install cuda","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:19:41.252069Z","iopub.execute_input":"2024-04-30T13:19:41.252790Z","iopub.status.idle":"2024-04-30T13:24:24.372121Z","shell.execute_reply.started":"2024-04-30T13:19:41.252755Z","shell.execute_reply":"2024-04-30T13:24:24.370869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Set DEBIAN_FRONTEND variable to avoid interactive prompts\nos.environ['DEBIAN_FRONTEND'] = 'noninteractive'\n\n!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n!sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n!wget http://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.3-450.51.06-1_amd64.deb\n!sudo dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.3-450.51.06-1_amd64.deb\n!sudo apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n!sudo apt-get update -y\n!sudo apt-get -y install cuda","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:24:27.816426Z","iopub.execute_input":"2024-04-30T13:24:27.816834Z","iopub.status.idle":"2024-04-30T13:26:28.826418Z","shell.execute_reply.started":"2024-04-30T13:24:27.816800Z","shell.execute_reply":"2024-04-30T13:26:28.825174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nmodel_name = model_checkpoint.split(\"/\")[-1]\nargs = Seq2SeqTrainingArguments(\n    f\"{model_name}-finetuned-pav1\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.001,\n    save_total_limit=3,\n    num_train_epochs=6,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=True,\n    fp16_full_eval=False  # Désactiver la précision en demi-précision pour l'évaluation\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:26:32.352166Z","iopub.execute_input":"2024-04-30T13:26:32.352574Z","iopub.status.idle":"2024-04-30T13:26:32.385906Z","shell.execute_reply.started":"2024-04-30T13:26:32.352542Z","shell.execute_reply":"2024-04-30T13:26:32.384888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"id":"139T2BuWlbqw","execution":{"iopub.status.busy":"2024-04-30T13:26:35.523701Z","iopub.execute_input":"2024-04-30T13:26:35.524073Z","iopub.status.idle":"2024-04-30T13:26:35.528694Z","shell.execute_reply.started":"2024-04-30T13:26:35.524043Z","shell.execute_reply":"2024-04-30T13:26:35.527729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Rouge expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n\n    # Note that other metrics may not have a `use_aggregator` parameter\n    # and thus will return a list, computing a metric for each sentence.\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n    # Extract a few results\n    result = {key: value * 100 for key, value in result.items()}\n\n    # Add mean generated length\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"id":"UmvbnJ9JIrJd","execution":{"iopub.status.busy":"2024-04-30T13:26:39.694841Z","iopub.execute_input":"2024-04-30T13:26:39.695728Z","iopub.status.idle":"2024-04-30T13:26:39.705121Z","shell.execute_reply.started":"2024-04-30T13:26:39.695694Z","shell.execute_reply":"2024-04-30T13:26:39.704137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:26:50.516528Z","iopub.execute_input":"2024-04-30T13:26:50.516902Z","iopub.status.idle":"2024-04-30T13:26:50.523493Z","shell.execute_reply.started":"2024-04-30T13:26:50.516873Z","shell.execute_reply":"2024-04-30T13:26:50.522478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"id":"imY1oC3SIrJf","execution":{"iopub.status.busy":"2024-04-30T13:26:53.925848Z","iopub.execute_input":"2024-04-30T13:26:53.926532Z","iopub.status.idle":"2024-04-30T13:26:55.176893Z","shell.execute_reply.started":"2024-04-30T13:26:53.926499Z","shell.execute_reply":"2024-04-30T13:26:55.175896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#aa93aa137a1a9d100aa3118a53d243fa4fe8543f","metadata":{"execution":{"iopub.status.busy":"2024-04-30T13:09:31.795214Z","iopub.status.idle":"2024-04-30T13:09:31.795523Z","shell.execute_reply.started":"2024-04-30T13:09:31.795371Z","shell.execute_reply":"2024-04-30T13:09:31.795383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"uNx5pyRlIrJh","outputId":"077e661e-d36c-469b-89b8-7ff7f73541ec","execution":{"iopub.status.busy":"2024-04-30T13:26:59.114823Z","iopub.execute_input":"2024-04-30T13:26:59.115272Z","iopub.status.idle":"2024-04-30T16:15:15.110289Z","shell.execute_reply.started":"2024-04-30T13:26:59.115239Z","shell.execute_reply":"2024-04-30T16:15:15.109400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"id":"G9juLa-klbqz","execution":{"iopub.status.busy":"2024-04-30T16:15:23.497746Z","iopub.execute_input":"2024-04-30T16:15:23.498446Z","iopub.status.idle":"2024-04-30T16:15:26.896401Z","shell.execute_reply.started":"2024-04-30T16:15:23.498410Z","shell.execute_reply":"2024-04-30T16:15:26.895202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"racha009/t5-small-checkpoint-finetuned-pav1","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"7Tw7Gzcmlbqz"},"execution_count":null,"outputs":[]}]}